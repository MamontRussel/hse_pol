{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simple Random Forest\n",
    "\n",
    "Этот блокнот составлен на основе большого блокнота, который доступен по этой [ссылке](https://www.kaggle.com/dansbecker/your-first-machine-learning-model). В нем присутству.т дополнительные комментарии и другие примеры работы алгоритма. Если хотите как следует разобраться с деревьями на базовом уровне - обязательно читайте."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загружаем наши данные\n",
    "\n",
    "Нашим датасетом будет информация о жилье в Мельбурне, которая включает в себя множество параметров, например, количество и размер этажей дома, год постройки, общая площадь, цена и многое другое (остальные столбцы, можете изучить самостоятельно)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Название файла, который нужно загрузить\n",
    "path = 'train.csv'\n",
    "\n",
    "#Загружаем данные\n",
    "home_data = pd.read_csv(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор цели предсказания\n",
    "\n",
    "В нашем случае, все более-менее очевидно. Это цена на дом. Обычно, цель предсказания помечают y."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = home_data.SalePrice"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выбор признаков (Features)\n",
    "\n",
    "Столбцы, которые есть в нашей модели и которые в последствии будут использованы для предсказания, называются признаками (features). В нашем случае, эти колонки будут определять стоимость дома. Обычно используются все колонки, кроме той на которую делается предсказание. Но иногда, лучше выбрать только часть из них.\n",
    "\n",
    "Мы будет использовать не все столбцы, чтобы алгоритм все считал быстрее."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_columns = ['LotArea', 'YearBuilt', '1stFlrSF', '2ndFlrSF', 'FullBath', 'BedroomAbvGr', 'TotRmsAbvGrd']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычно, такие данные обозначаются X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = home_data[feature_columns]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Строим модель\n",
    "\n",
    "Мы будем использовать модуль scikit-learn для создания модели. Scikit-learn одна из самых популярных библиотек для моделирования данных, хранящихся в датафреймах. \n",
    "\n",
    "Для построения модели нужно выполнить следующие шаги: <br>\n",
    "\n",
    "Define: Какого типа будет модель? Дерево решений? Какой-то другой тип?<br>\n",
    "Fit: запускаем модель на тренировочных данных (обучаем ее), чтобы алгоритм нашел в них некие закономерности и зависимости.<br>\n",
    "Predict: Предсказать результат.<br>\n",
    "Evaluate: Определить насколько точным оказалось предсказывание, оценить качество модели<br>\n",
    "\n",
    "В нашем примере, мы будет использовать дерево решений из scikit-learn и тренировать модель с признаками, выделенными ранее. Импортируем функцию DecisionTreeRegressort"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Инициализируем модель и обучим ее на наших данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(criterion='mse', max_depth=None, max_features=None,\n",
       "           max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "           min_impurity_split=None, min_samples_leaf=1,\n",
       "           min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "           presort=False, random_state=None, splitter='best')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Инициалазируем модель\n",
    "home_model = DecisionTreeRegressor()\n",
    "\n",
    "# Обучаем модель\n",
    "home_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Нам выше вывелась информация о нашем регрессоре и с какими парамтерами он обучался.\n",
    "\n",
    "Мы обучили модель. Но как хорошо она обучилась? Сравним предсказанные значения с полученными "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Наше предсказание: [136000. 287090. 146500.  84500. 185000. 175000. 210000. 266500. 142125.\n",
      " 147500.]\n",
      "Реальная цена домов: [136000, 287090, 145000, 84500, 185000, 175000, 210000, 266500, 142125, 147500]\n"
     ]
    }
   ],
   "source": [
    "print(\"Наше предсказание:\", home_model.predict(X_train.tail(10)))\n",
    "print(\"Реальная цена домов:\", y_train.tail(10).tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результаты практически похожи, но кое-где есть отличия. И мы отображаем всего 10 элементов из всей выборки. Посмотрим насколько правильно нам предсказала модель для всей выборки. Мы можем, конечно, пройтись в цикле по всем эелементам и посчитать ошибку у каждого. Но у нас могут быть как хорошие, так и плохие предсказания. И в идеальном случае нам нужна одна метрика, которая скажет как хорошо мы обучили данные.\n",
    "\n",
    "Воспульзуемся метрикой MEA (Mean Absolute Error) - Cредняя Aбсолютная Ошибка. Ее можно представить в таком виде: ошибка=реальная цена − предсказанная цена. Напрмиер, если цена дома 150 000, мы предсказали цены в 100 000, то ошибка будет 50 000. Для ошибок в отрицательную сторону берем модуль. Это одна из простейших метрик.\n",
    "\n",
    "Импортируем нужную функцию опять же из sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Делаем предсказание и передаем в функцию предсказанное и реальное значение"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62.35433789954339\n"
     ]
    }
   ],
   "source": [
    "pred = home_model.predict(X_train)\n",
    "mae = mean_absolute_error(pred, y_train)\n",
    "print(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Получили ошибку 62.35 (долларов), что было бы очень хорошим результатом, если не одно но."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Валидация данных\n",
    "\n",
    "Мы только что проверяли обученную модель на тех же данных, на которых мы ее и обучали. И это неверно. Т.к. в нашем случае нам нужно предсказывать цены новых домов, которых не было в обучающей выборке. Поэтому не удивительно, что MAE = 62. \n",
    "\n",
    "Опишем эту проблему таким примером. У нас есть большой рынок жилья. Цена жилья не связана с цветом входной двери. Но в нашей обучающей выборке у всех домов с высокой ценой была зеленая дверь. Модель увидит эту зависимость и будет предсказаывать для новых домой с зеленой дверью высокую цену, что не будет корректным. Но при валидации модели на обучающих даныех мы получили маленькую ошибку и посчитали, что модель натренирована хорошо, но если бы мы это сделали на тестовых данных, то увидели бы что ошибка велика и нужно переделать модель."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучающие и тестовые выборки\n",
    "\n",
    "Давайте разделим наши данные на 2 части: обучающую выборку и тестовую. Воспльзуемся опять модулей skilearn и функцией отттуда train_test_split. Импортируем функцию"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разобъем данные как для X, так и для  y. Каждый раз разбитие происходит рандомно, мы можем только указать в какой пропорции мы хотим разбить наши данные, например 30% всей выборки на обучение, остальное на тест."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# заполнили массивы с нашими данными \n",
    "X = home_data[feature_columns]\n",
    "y = home_data.SalePrice\n",
    "\n",
    "# Делим\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим сколько данных попала в обучающую и тестовые выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1095\n"
     ]
    }
   ],
   "source": [
    "print(len(train_X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "365\n"
     ]
    }
   ],
   "source": [
    "print(len(test_X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В обучающей 1095, а в тестовой 365 домов.\n",
    "\n",
    "Теперь как и в прошлый раз построим модель и посчитаем MAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32996.23561643835\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем модель\n",
    "home_model = DecisionTreeRegressor()\n",
    "# Обучаем модель\n",
    "home_model.fit(train_X, train_y)\n",
    "\n",
    "# Предсказываем цены и считаем MAE\n",
    "val_predictions = home_model.predict(test_X)\n",
    "print(mean_absolute_error(test_y, val_predictions))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воу. 32691 долларов. Это большая ошибка по сравнению с нашей изначальной ошибкой на обучающей выборке. И выходит что для новых домов, наша модель плохо предсказывала бы цены\n",
    "\n",
    "Наша модель обучается не очень оптимально, но к счастью есть несколько способов как можно улучшить модель, например эксперементирую с параметрами модели"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Эксперементируем с моделями\n",
    "\n",
    "Можно сказать что мы столкнулись с проблемой переобучения (overfitting), когда модель предсказывает обучающие данные практически идеально, а тестовые данные и другие данные предсказывате плохо.\n",
    "\n",
    "Существует еще и недообучение (underfitting), когда модель не может найти параметры по которым можно разделить данные и она плохо предсказывает даже на обучающих данных.\n",
    "\n",
    "Так как мы используем DecisionTreeRegressor, т.е. дерево, в случае overfitting наше дерево имеет очень маленькую глубину, а при underfitting получаем очень глубокие деревья. Поэтому мы может попробовать регулировать глубину дерева. В DecisionTreeRegressor есть параметер max_leaf_nodes, который мы можем контролировать. Чем больше листьев мы разрешим модели делать, тем дальше мы уйдет от underfiting, но будем приближаться к overfitting, т.е. в идеальном случае нам нужно подобрать примерно средную глубину для модели.\n",
    "\n",
    "Создадим функцию, которая будет строить для нас деревеья с различным параметром max_leaf_nodes. А замерять модели будем снова через MAE."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mae(max_leaf_nodes, train_X, test_X, train_y, test_y):\n",
    "    # инициализируем модель с параметром max_leaf_node, который мы передали в функцию\n",
    "    model = DecisionTreeRegressor(max_leaf_nodes=max_leaf_nodes, random_state=0)\n",
    "    # обучаем модель на обучающих данных\n",
    "    model.fit(train_X, train_y)\n",
    "    # предсказываем на тестовых данных\n",
    "    preds_val = model.predict(test_X)\n",
    "    # считаем MAE\n",
    "    mae = mean_absolute_error(test_y, preds_val)\n",
    "    # возвращем значение ошибки\n",
    "    return(mae)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В функцию мы соответственно передаем количество листов, которые мы хотим и обучающие и тестовые выборки. Сделаем небольшой цикл по различный значением глубины от 5 до 5000 и выведем результаты."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Максимальная глубина дерева: 5  \t\t MEA:  35190\n",
      "Максимальная глубина дерева: 10  \t\t MEA:  30616\n",
      "Максимальная глубина дерева: 50  \t\t MEA:  27825\n",
      "Максимальная глубина дерева: 100  \t\t MEA:  28653\n",
      "Максимальная глубина дерева: 500  \t\t MEA:  32662\n",
      "Максимальная глубина дерева: 1000  \t\t MEA:  33385\n",
      "Максимальная глубина дерева: 5000  \t\t MEA:  33382\n"
     ]
    }
   ],
   "source": [
    "# сравниваем различне значения MAE для различной глубины деревьев\n",
    "for max_leaf_nodes in [5, 10, 50, 100, 500, 1000, 5000]:\n",
    "    my_mae = get_mae(max_leaf_nodes, train_X, test_X, train_y, test_y)\n",
    "    print(\"Максимальная глубина дерева: %d  \\t\\t MEA:  %d\" %(max_leaf_nodes, my_mae))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Как мы видим, самый лучший результат мы получили для глубины 50, но при этом ошибка досточно большая чтобы искажать предсказания для новых данных"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest\n",
    "\n",
    "Дерево решений оставляет с серьезным выбором. Глубокое дерево с overfitting с несколькими домами в каждом листе или мелкое дерево с несколькими листами, которое не может определить параметры и разделить данные. И все это с приличной ошибкой.\n",
    "\n",
    "Некоторые другие модели деревьев смогли решить эту проблему и уменьшить при этом итоговую ошибку. Попробуем взять Random Forest. Он использует множество деревьев и делает предсказание путем усреднения прогнозов каждого дерева компонентов.\n",
    "\n",
    "Попробуем использовать Random Forest на наших данных. Импортируем его из модуля sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rogovich\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Строим теперь модель с тем же параметрами и данными как в DecissionTreeRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24346.620065231575\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем модель\n",
    "forest_model = RandomForestRegressor(random_state=1)\n",
    "# Обучаем модель\n",
    "forest_model.fit(train_X, train_y)\n",
    "# Делаем предсказание\n",
    "melb_preds = forest_model.predict(test_X)\n",
    "# Посчитаем и выведем MAE\n",
    "print(mean_absolute_error(test_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ошибка уменьшилась, но все равно составляет 24 тысячи. Можно продолжить дальше эксперементировать с моделью, изменяя параметры или увеличивая обучающую выборку. \n",
    "\n",
    "Давайте изменим параметр n_estimators, который отвечает за количество деревьев в модели ( не путать с количеством листьев в DecissionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23009.206570906717\n"
     ]
    }
   ],
   "source": [
    "# Инициализируем модель\n",
    "forest_model = RandomForestRegressor(n_estimators = 100, random_state=1)\n",
    "# Обучаем модель\n",
    "forest_model.fit(train_X, train_y)\n",
    "# Делаем предсказание\n",
    "melb_preds = forest_model.predict(test_X)\n",
    "# Посчитаем и выведем MAE\n",
    "print(mean_absolute_error(test_y, melb_preds))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Уже 23 тысячи. Много это или мало? Можно ли остановиться? \n",
    "\n",
    "Конечно, мы всегда стараемся минимизировать нашу ошибку, но это и не всегда возможно. Возможно, здесь лучше справится другая модель. Так же мы взяли очень мало признаков, при чем не основываясь на какой-то особой теории - возможно, преобразование наших признаков или же их замена, улучшили бы качество."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "С остальными параметрами можно ознакомиться в [документации](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestClassifier.html) функции"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
