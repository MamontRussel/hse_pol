{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Титаник: Выбор модели\n",
    "\n",
    "Рассмотрим данные о пассажирах с печально известного Титаника. У нас есть неполные данные о 890 пассажирах. Составим несколько моделей выживания и сравним их точность. Все шаги можно посмотреть по ссылке выше или в блокноте Титаник: Подготовка данных.\n",
    "\n",
    "Основная часть блокнота со всеми комментариями доступна [здесь](https://www.kaggle.com/startupsci/titanic-data-science-solutions/notebook).\n",
    "Также мы уже обработали данные и убрали из них все вещественные и строковые значения.\n",
    "\n",
    "Импортируем основные модули."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# анализ данных\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random as rnd\n",
    "\n",
    "# машинное обучение\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn import metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим подготовленные данные из файлов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('train_upd.csv')\n",
    "test_df = pd.read_csv('test_upd.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  Age*Class\n",
       "0         0       3    0    1     0         0      1        0          3\n",
       "1         1       1    1    2     3         1      3        0          2\n",
       "2         1       3    1    1     1         0      2        1          3\n",
       "3         1       1    1    2     3         0      3        0          2\n",
       "4         0       3    0    2     1         0      1        1          6"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# изучим данные\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Title</th>\n",
       "      <th>IsAlone</th>\n",
       "      <th>Age*Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>892</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>893</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>894</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>895</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>896</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Pclass  Sex  Age  Fare  Embarked  Title  IsAlone  Age*Class\n",
       "0          892       3    0    2     0         2      1        1          6\n",
       "1          893       3    1    2     0         0      3        0          6\n",
       "2          894       2    0    3     1         2      1        1          6\n",
       "3          895       3    0    1     1         0      1        1          3\n",
       "4          896       3    1    1     1         0      3        0          3"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Базовая модель (Baseline)\n",
    "\n",
    "Под базовой моделью (baseline) подразумевается какая-то несложная модель или константное предсказание, от которого мы не ждем суперкачества, но на которую мы ориентируемся впоследствии (стараемся предсказать лучше, чем она). \n",
    "\n",
    "Самая простая базовая модель - константное предсказание. Мы просто берем какое-то значение и используем его (значение одного из классов для всех наблюдений для задачи классификации или среднее значение y для задач регрессии). \n",
    "\n",
    "### Accuracy\n",
    "\n",
    "Accuracy представляет собой простую метрику для задач классификации, которая считает количество верно угаданных предсказаний относительно общего количество элементов. Например, у нас есть y = [0 1 0 0 1 0 1 1]. Мы предсказали y_pred = [0 1 0 1 1 0 0 1]. 6 из 8 правильных, получим accuracy score = 0.75.\n",
    "\n",
    "Также для задач классификации можно использовать метрику Presicion, F1-score или Log-loss. С ними можно ознакомится по [ссылке](https://scikit-learn.org/stable/modules/model_evaluation.html#classification-metrics).\n",
    "\n",
    "Для задач регрессии можно использовать следующие метрики:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Root Mean Squared Error (RMSE)\n",
    "\n",
    "Root Mean Squared Error или среднеквадратичное отклонение. Одна из основных метрик для задач регрессии, которая при этом является относительно простой. Она считается по следующей формуле:<br>\n",
    "![alternate text](https://wikimedia.org/api/rest_v1/media/math/render/svg/15619dfbb9a470d310c1bc08fb61d4fb1187d057)\n",
    "\n",
    "Т.е. представляет собой квадратный корень из разности квадратов предсказанного и реального значений."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mean Absolute Error (MAE)\n",
    "\n",
    "В MAE ошибка считается как среднее от абсолютной разницы между реальным и предсказанным значений. MAE это линейная оценка, что означает что все индивидуальные разницы в среднем взвешены одинаково. Например, разница между 10 и 0 будет двойной разницей между 5 и 0. Что не будет верно в случае RMSE. Математически формулы высчитывается вот так:<br> \n",
    "![alternate text](https://cdn-images-1.medium.com/max/1600/1*8DXbECB9pnKxTpIvuVD-vg.png)\n",
    "\n",
    "\n",
    "Почитать подробнее про метрики для регрессии и базовую модель можно по этой [ссылке](https://towardsdatascience.com/how-to-select-the-right-evaluation-metric-for-machine-learning-models-part-1-regrression-metrics-3606e25beae0).\n",
    "\n",
    "Так как у нас задача классификации, то будем использовать метрику аccuracy.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submission\n",
    "\n",
    "Попробуем загрузить на Kaggle первый сабмишн и одновременно создать константную базовую модель. Если изучить данные, то видно что только 38% всех пассажиров из обучающей выборки выжили. Если такая же пропорция сохранится для тестовой выборки, то можно предположить что большинство людей умерли в тестовой выборке. Поэтому сделаем констатное предсказание, что `ВСЕ` пассажиры умерли и сохраним его в csv файл для дальнейшей загрузки на Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Заполняем нулями список выживших, точнее уже погибших\n",
    "Y_pred = list(0 for i in range(len(test_df)))\n",
    "\n",
    "submission_dead = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "\n",
    "submission_dead.to_csv('submission_dead.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сразу сделаем второй сабмишн. Изучив данные о тех кто выжил, можно заметить что в основном выжили женщины:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sex</th>\n",
       "      <th>Survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.742038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.188908</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Sex  Survived\n",
       "1    1  0.742038\n",
       "0    0  0.188908"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[[\"Sex\", \"Survived\"]].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы закодировали женский пол как 1 и мужской как 0 (в блокноте Титаник: Подготовка данных). Почти 75% женщин выжили, что хорошо соотносится с фразой \"сначала женщины и дети\".\n",
    "\n",
    "Поэтому можно сделать новое предсказание, что погибли все, кроме женщин."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = list(test_df.Sex[i] for i in range(len(test_df)))\n",
    "\n",
    "submission_woman = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "\n",
    "submission_woman.to_csv('submission_woman.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Предсказания можно загрузить на Kaggle. Предсказание, где женщины выжили, должно набрать больше очков. Т.е. мы улучшим свое предсказание относительно базовой модели. Сделать их можно по следующему [адресу](https://www.kaggle.com/c/titanic/submit). Наше score 0.62679 для случая когда все погибли. А score для случая когда все женщины выжили: 0.76555. Улучшили результат на 0.13876 относительно базавой модели."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model, predict и solve\n",
    "\n",
    "Когда мы обработали весь дасет, убрав из него все вещественные и строковые значения, можно заняться обучением модели и предсказанием выживания пассажиров. Для начала выберем алгоритм предсказания. Сейчас существует боллее 60 алгоритмов. Чтобы выбрать правильный, нужно понимать тип задачи и решение, которое удовлетворит нашим условиям. У нас задача классификации и регрессии. Нужно понять соотношение между результатом (выжил или нет) и другими переменными или признаками (пол, возраст, порт, класс и т.д.). По факту мы осуществляем обучение с учителем, т.к. обучение идет с известным результатом (выжил или нет). С этими параметрами, мы можем ограничить список подходящих нам алгоритмов. Остановимся в итоге на этих алгоритмах:\n",
    "\n",
    "* Логистическая регрессия\n",
    "* KNN или k-Ближайших соседей (k-Nearest Neighbors)\n",
    "* Наивный Байес\n",
    "* Дерево решений\n",
    "* Случайный лес\n",
    "* Перцептрон\n",
    "* XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# заполнили массивы с нашими данными \n",
    "X = train_df.drop(\"Survived\", axis=1)\n",
    "y = train_df[\"Survived\"]\n",
    "X_test  = test_df.drop(\"PassengerId\", axis=1).copy()\n",
    "\n",
    "# Делим\n",
    "train_X, test_X, train_y, test_y = train_test_split(X, y, random_state = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Посмотрим как наши данные разбились:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((668, 8), (668,), (223, 8), (223,), (418, 8))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_X.shape, train_y.shape, test_X.shape, test_y.shape, X_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "668 элементов в обучающей и 223 элемента в тестовой выборке.\n",
    "\n",
    "Начнем с Логистической регрессии. Ее советуют использовать в самом начале. Эта статистическая модель, используемая для предсказания вероятности возникновения некоторого события путём подгонки данных к логистической кривой.\n",
    "\n",
    "Давайте обучим модель на нашей обучающей выборке и предскажем людям из тестовой выборке выжили они или нет. А потом посмотрим насколько точно она это сделала."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76.68"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Логистическая регрессия\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(train_X, train_y)\n",
    "pred = logreg.predict(test_X)\n",
    "\n",
    "acc_log = round(metrics.accuracy_score(test_y, pred) * 100, 2)\n",
    "acc_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделаем первый сабмишн на Kaggle с Логистической регрессией. Сохраним файл как csv, а потом загрузим его на сайт, чтобы узнать насколько точно мы предсказали."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = logreg.predict(X_test)\n",
    "\n",
    "submission_LR = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "\n",
    "submission_LR.to_csv('submission_LR.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Продолжим выяснять какая модель лучше. На очереди KNN. \n",
    "\n",
    "Запустим алгоритм по трем ближайщим соседям."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "81.61"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# KNN\n",
    "\n",
    "knn = KNeighborsClassifier(n_neighbors = 3)\n",
    "knn.fit(train_X, train_y)\n",
    "pred = knn.predict(test_X)\n",
    "\n",
    "acc_knn = round(metrics.accuracy_score(test_y, pred) * 100, 2)\n",
    "acc_knn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Результат KNN уже лучше чем у Логистической регрессии. Попробуем теперь Наивный Байес."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.65"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Наивный Байес\n",
    "\n",
    "gaussian = GaussianNB()\n",
    "gaussian.fit(train_X, train_y)\n",
    "pred = gaussian.predict(test_X)\n",
    "\n",
    "acc_gaussian = round(metrics.accuracy_score(test_y, pred) * 100, 2)\n",
    "acc_gaussian"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Хм. Результат ухудшился, но ничего. У нас есть еще несколько модель. Следующей будет Перцептрон. Это самая простейшая модель нейронной сети. \n",
    "\n",
    "Перцептрон - это алгоритм обучения с учителем двоичных классификаторов (функций, которые могут определять, принадлежит ли вход, представленный вектором чисел, какому-то определенному классу или нет). Это тип линейного классификатора, то есть алгоритм классификации, который делает свои предсказания на основе функции линейного предиктора, объединяющей набор весов с вектором признаков.\n",
    "\n",
    "Дополнительно почитать про перцептроны можно [здесь](http://neuralnet.info/chapter/персептроны/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mamont/anaconda3/lib/python3.6/site-packages/sklearn/linear_model/stochastic_gradient.py:128: FutureWarning: max_iter and tol parameters have been added in <class 'sklearn.linear_model.perceptron.Perceptron'> in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  \"and default tol will be 1e-3.\" % type(self), FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "74.89"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Перцептрон\n",
    "\n",
    "perceptron = Perceptron()\n",
    "perceptron.fit(train_X, train_y)\n",
    "pred = perceptron.predict(test_X)\n",
    "\n",
    "acc_perceptron = round(metrics.accuracy_score(test_y, pred) * 100, 2)\n",
    "acc_perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Немного лучше. Попробуем Дерево решений.\n",
    "\n",
    "Эта модель использует дерево решений в качестве прогнозирующей модели, которая соединяет признаки (ветви дерева) с выводами о принадлежности к какому-то из классов (листья дерева). Древовидные модели, в которых целевая переменная может принимать конечный набор значений, называются деревьями классификации; в этих древовидных структурах листья представляют метки классов, а ветви представляют соединения функций, которые ведут к этим меткам классов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "82.06"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Дерево решений\n",
    "\n",
    "decision_tree = DecisionTreeClassifier()\n",
    "decision_tree.fit(train_X, train_y)\n",
    "pred = decision_tree.predict(test_X)\n",
    "\n",
    "acc_decision_tree = round(metrics.accuracy_score(test_y, pred) * 100, 2)\n",
    "acc_decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Самой популярной моделью является Случайный лес. Алгоритм заключается в использовании ансамбля решающих деревьев. Алгоритм сочетает в себе две основные идеи: метод бэггинга Бреймана, и метод случайных подпространств, предложенный Tin Kam Ho. Алгоритм применяется для задач классификации, регрессии и кластеризации. Основная идея заключается в использовании большого ансамбля решающих деревьев, каждое из которых само по себе даёт очень невысокое качество классификации, но за счёт их большого количества результат получается хорошим.\n",
    "\n",
    "Укажем максимальное количество деревьев равным 100."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84.3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Случайный Лес\n",
    "\n",
    "random_forest = RandomForestClassifier(n_estimators=100)\n",
    "random_forest.fit(train_X, train_y)\n",
    "pred = random_forest.predict(test_X)\n",
    "\n",
    "acc_random_forest = round(metrics.accuracy_score(test_y, pred) * 100, 2)\n",
    "acc_random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Последней моделью будет XGBoost -  библиотека, реализующая методы градиентного бустинга. Она работает очень похоже на Случайный лес, тоже создавая много неглубоких деревьев. Идея градиентного бустинга состоит в построении ансамбля последовательно уточняющих друг друга элементарных моделей. n-ная элементарная модель обучается на “ошибках” ансамбля из n-1 моделей, ответы моделей взвешенно суммируются. “Ошибки” здесь в кавычках, поскольку на самом деле каждая последующая модель приближает антиградиент функции потерь, который не обязательно равен разности фактических и предсказанных значений (т.е. ошибке в буквальном смысле). \n",
    "\n",
    "Чуть больше информации можно изучить по этой [ссылке](http://biostat-r.blogspot.com/2016/08/xgboost.html). Не пугайтесь что там R, теория и применение справедливо и для питона.\n",
    "\n",
    "Мы будем использовать классификатор с 100 деревьями."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/Mamont/anaconda3/lib/python3.6/site-packages/sklearn/preprocessing/label.py:151: DeprecationWarning: The truth value of an empty array is ambiguous. Returning False, but in future this will result in an error. Use `array.size > 0` to check that an array is not empty.\n",
      "  if diff:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "82.96"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# XGBoost\n",
    "\n",
    "xgb = XGBClassifier(n_estimators=100)\n",
    "xgb.fit(train_X,train_y)\n",
    "pred = xgb.predict(test_X)\n",
    "\n",
    "acc_xgb = round(metrics.accuracy_score(test_y, pred) * 100, 2)\n",
    "acc_xgb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оценка моделей\n",
    "\n",
    "Мы теперь можем оценить все модели и выбрать самую лучшую для нашей задачи. С небольшим отрывом побеждает Случайный лес. Его то мы и используем для финального сабмита на Kaggle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>84.30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost</td>\n",
       "      <td>82.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>82.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>81.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>76.68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>74.89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>72.65</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Model  Score\n",
       "2        Random Forest  84.30\n",
       "6              XGBoost  82.96\n",
       "5        Decision Tree  82.06\n",
       "0                  KNN  81.61\n",
       "1  Logistic Regression  76.68\n",
       "4           Perceptron  74.89\n",
       "3          Naive Bayes  72.65"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models = pd.DataFrame({\n",
    "    'Model': ['KNN', 'Logistic Regression', \n",
    "              'Random Forest', 'Naive Bayes', 'Perceptron', \n",
    "              'Decision Tree', 'XGBoost'],\n",
    "    'Score': [acc_knn, acc_log, \n",
    "              acc_random_forest, acc_gaussian, acc_perceptron,\n",
    "              acc_decision_tree, acc_xgb]})\n",
    "models.sort_values(by='Score', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сохраним в csv наш сабмишн."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred = random_forest.predict(X_test)\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "        \"PassengerId\": test_df[\"PassengerId\"],\n",
    "        \"Survived\": Y_pred\n",
    "    })\n",
    "\n",
    "submission.to_csv('submission_RF.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Теперь у нас есть 4 сабмишена. Стоит напомнить, что в день можно совершать до 10 сабмишинов. Теперь можно загрузить их на сайт и проверить какие результаты у нас получились и отметить насколько улучшились наши предсказания относительно базовой модели. На Логистической регрессии получили 0.77511."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
